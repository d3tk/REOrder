run_name: longformer-base_IN1K_patch-rl-row_pemb-row-learned_lr1e-4_po-lr-1e-5_warm5_bs576_cls_pm99_delayed_triangular-no_aug

log_rules:
  project: $INSERT_PROJECT_NAME
  entity: $INSERT_ENTITY_NAME
  log: True
  log_interval: 20

# MODEL PARAMETERS
model_type: longformer
size: base
model:
  img_size: 224
  patch_size: 16
  in_chans: 3
  num_classes: 1000
  patch_dir: RL
  pe_order: ROW
  pe_mode: learned
  

# TRAINING PARAMETERS
training:
  compile: True
  dataset:
    name: imagenet-1k
    subset: 1
    data_transforms:
      - name: Resize
        kwargs:
          size: 256
      - name: CenterCrop
        kwargs:
          size: 224
      - name: ToTensor
      - name: Normalize
        kwargs:
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
    target_transforms: null
  dist: True
  shuffle: True
  seed: 42
  batch_size: 576
  num_epochs: 100
  num_workers: 4
  pin_memory: True
  drop_last: True
  replacement: False
  num_samples: null
  clip_grad: 5.0
  persistent_workers: True

## VALIDATION PARAMETERS
validation:
  dataset:
    name: imagenet-1k
    subset: 1
    data_transforms:
      - name: Resize
        kwargs:
          size: 256
      - name: CenterCrop
        kwargs:
          size: 224
      - name: ToTensor
      - name: Normalize
        kwargs:
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
    target_transforms: null
  dist: True
  shuffle: False
  batch_size: ${training.batch_size}
  num_workers: ${training.num_workers}
  pin_memory: True
  drop_last: False
  replacement: False
  persistent_workers: False
  num_samples: null

reinforce:
  policy_optimizer:
    name: AdamW
    base_lr: 1.0e-5
    weight_decay: 0.03
    betas: [0.9, 0.999]
    grad_scale: True
    init_scale: 1024
    autocast: True
  start_after: 15
  policy_gumbel_temp_scheduler:
    starting_temp: 0.2
    ending_temp: 0
    running_epochs: 30
    decay_type: triangular
  momentum: 0.99
  method: gumbel
  reward_type: xent
  logit_init: ROW

## OPTIMIZER
optimizer:
  name: AdamW
  base_lr: 1.0e-4
  weight_decay: 0.03
  betas: [0.9, 0.999]
  grad_scale: True
  init_scale: 1024
  autocast: True
  
## SCHEDULER
scheduler:
  warmup_epochs: 5
  warmup_factor: 1
  name: cosine
  min_lr_ratio: 0.01

## SAVING CHECKPOINTS
save_every: 10